
import logging
import json
import csv
import os
import sys

from pbsmrtpipe.testkit.core.base import TestBase
from pbcommand.models import FileTypes
from pbcore.io import GffReader, ReferenceSet

from pysiv2.custom import utils as u
from pysiv2.io.datastore import DataStore
from pysiv2.io.entrypoints import EntryPoints

__author__ = "Nat Echols"

log = logging.getLogger(__name__)

# maximum number of bases to check
MAX_BASES = 50000
STRANDS = ['+', '-']


class TestModificationsOutput(TestBase):
    """
    Tests for consistency of files output by ipdSummary.
    """

    @classmethod
    def setUpClass(cls):
        super(TestModificationsOutput, cls).setUpClass()
        datastore = DataStore.from_job_path(cls.job_dir)
        entrypoints = EntryPoints.from_job_path(cls.job_dir)
        cls.h5_file = None
        cls.bw_file = None
        cls.gff_file = None
        for file_id, file_info in datastore.get_file_dict().iteritems():
            if file_info.is_chunked:
                continue
            if file_info.file_type_id == FileTypes.GFF.file_type_id:
                with GffReader(file_info.path) as gff:
                    for header in gff.headers:
                        if header.startswith("##source ipdSummary"):
                            cls.gff_file = file_info.path
            elif file_info.file_type_id == FileTypes.H5.file_type_id:
                cls.h5_file = file_info.path
            elif file_info.file_type_id == FileTypes.BIGWIG.file_type_id:
                cls.bw_file = file_info.path
        with GffReader(cls.gff_file) as gff:
            cls.gff_records = [rec for rec in gff]
        cls.gff_dict = {}
        for rec in cls.gff_records:
            cls.gff_dict[(rec.seqid, rec.start, rec.strand)] = rec
        ref = entrypoints.data['eid_ref_dataset']
        cls.seqids = []
        with ReferenceSet(ref) as rs:
            for i_ref, ctg in enumerate(rs):
                cls.seqids.append(ctg.id)

    def test_basemods_h5(self):
        """
        Check that the ipdRatios in the h5 file are consistent with the GFF
        file.
        """
        import h5py
        f = h5py.File(self.h5_file)
        for seqid in f.keys():
            g = f[seqid]
            for i in range(len(g['tpl'])):
                strand = STRANDS[g['strand'][i]]
                base = g['tpl'][i]
                ipdRatio = g['ipdRatio'][i]
                key = (seqid, base, strand)
                if key in self.gff_dict:
                    gff_rec = self.gff_dict[key]
                    self.assertAlmostEqual(gff_rec.IPDRatio, ipdRatio, places=2)

    def test_bigwig(self):
        """
        Check that encoded ipdRatios in the BigWig output are consistent with
        modified bases in the GFF file (albeit with lower precision).
        """
        import pyBigWig
        f = pyBigWig.open(self.bw_file)
        for (seqid,start,strand), rec in self.gff_dict.iteritems():
            s = int(f.values(seqid, start-1, start)[0])
            ipd_minus = (s % 65536) / 100.0
            ipd_plus = (s >> 16) / 100.0
            if strand == "+":
                self.assertAlmostEqual(rec.IPDRatio, ipd_plus, places=1)
            else:
                self.assertAlmostEqual(rec.IPDRatio, ipd_minus, places=1)
